{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Machine Learning Framework for Stroke Prediction: Balancing Precision and Recall in Healthcare Analytics (Master Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill\n",
    "import scrapbook\n",
    "from itertools import product\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', context='talk')\n",
    "\n",
    "stroke_data = dataset[dataset['stroke'] == 1].drop('id', axis=1).describe().T\n",
    "no_stroke_data = dataset[dataset['stroke'] == 0].drop('id', axis=1).describe().T\n",
    "\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "sns.heatmap(stroke_data[['mean']], annot=True, cmap=cmap, linewidths=0.8,\n",
    "            linecolor='gray', cbar=True, fmt='.2f', ax=axes[0],\n",
    "            annot_kws={\"size\":14})\n",
    "axes[0].set_title('Stroke Suffered', fontsize=16, pad=16)\n",
    "axes[0].set_ylabel('')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].tick_params(labelsize=12)\n",
    "\n",
    "sns.heatmap(no_stroke_data[['mean']], annot=True, cmap=cmap, linewidths=0.8,\n",
    "            linecolor='gray', cbar=True, fmt='.2f', ax=axes[1],\n",
    "            annot_kws={\"size\":14})\n",
    "axes[1].set_title('No Stroke Suffered', fontsize=16, pad=16)\n",
    "axes[1].set_ylabel('')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].tick_params(labelsize=12)\n",
    "\n",
    "fig.suptitle('Mean Statistics Comparison for Stroke Data', fontsize=18, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this insight, we can notice that people that are more likely to suffer from a stroke are the ones that are elder and have a high averge glucose level, indicating diabetes. Moreover, heart disease and hypertension can contribute to being affected by a stroke in the near future. Thus, BMI doesn't seem as relevant as the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dataset['stroke'].value_counts()\n",
    "labels = ['No Stroke Suffered', 'Stroke Suffered']\n",
    "percentages = [counts[0] / counts.sum() * 100, counts[1] / counts.sum() * 100]\n",
    "\n",
    "colors = ['#66b3ff', '#ff9999']\n",
    "explode = (0.1, 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    percentages,\n",
    "    labels=labels,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    explode=explode,\n",
    "    colors=colors,\n",
    "    shadow=True,\n",
    "    wedgeprops={'edgecolor': 'black', 'linewidth': 1}\n",
    ")\n",
    "\n",
    "ax.set_title('Stroke Events (%)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are dealing with a highly imbalanced dataset, where only 4.9% of the samples are from people that have suffered a stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 201 nulls in the BMI column that we have to deal with. We have several options: remove the affected rows, remove the affected columns, replace with the mean, or train a model to predict the missing BMI. Let's take a look at the mean of stroke and non-stroke data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['bmi'] = dataset['bmi'].fillna(dataset['bmi'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are no duplicated rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ID column should also be removed as it doesn't pose relevancy to the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    col for col in dataset.columns \n",
    "    if dataset[col].dtype == 'object' or dataset[col].nunique() <= 10 \n",
    "]\n",
    "\n",
    "\n",
    "numerical_features = [col for col in dataset.columns if col not in categorical_features]\n",
    "\n",
    "categorical_features = [dataset.columns.get_loc(col) for col in categorical_features]\n",
    "numerical_features = [dataset.columns.get_loc(col) for col in numerical_features]\n",
    "categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    col for col in dataset.columns\n",
    "    if dataset[col].dtype == 'object' or dataset[col].nunique() <= 10\n",
    "]\n",
    "\n",
    "plots_per_row = 3\n",
    "rows = math.ceil(len(categorical_cols) / plots_per_row)\n",
    "\n",
    "fig, axes = plt.subplots(rows, plots_per_row, figsize=(5 * plots_per_row, 4 * rows))\n",
    "\n",
    "axes = axes if isinstance(axes, np.ndarray) else [[axes]]\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    r = i // plots_per_row  \n",
    "    c = i % plots_per_row   \n",
    "    sns.countplot(x=col, data=dataset, palette='viridis', ax=axes[r][c])\n",
    "    axes[r][c].set_title(f\"Distribution of {col}\")\n",
    "    axes[r][c].tick_params(axis='x', rotation=45)\n",
    "\n",
    "total_subplots = rows * plots_per_row\n",
    "for j in range(i+1, total_subplots):\n",
    "    r = j // plots_per_row\n",
    "    c = j % plots_per_row\n",
    "    axes[r][c].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here, we can think of some feature engineering steps. For instance, there is one individual with 'Other' gender category. Since there isn't a lot of data for the 'Other' category, it will pose extra challange for a model. Thus, the 'Other' individual has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['gender'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    col for col in dataset.columns\n",
    "    if np.issubdtype(dataset[col].dtype, np.number) and dataset[col].nunique() > 10\n",
    "]\n",
    "\n",
    "\n",
    "plots_per_row = 3\n",
    "rows = math.ceil(len(numerical_cols) / plots_per_row)\n",
    "\n",
    "fig, axes = plt.subplots(rows, plots_per_row, figsize=(5 * plots_per_row, 4 * rows))\n",
    "axes = np.atleast_2d(axes)  \n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    r = i // plots_per_row\n",
    "    c = i % plots_per_row\n",
    "    sns.histplot(data=dataset, x=col, kde=True, ax=axes[r, c], color='skyblue')\n",
    "    axes[r, c].set_title(f\"Distribution of {col}\")\n",
    "    axes[r, c].set_xlabel(col)\n",
    "\n",
    "total_subplots = rows * plots_per_row\n",
    "for j in range(i + 1, total_subplots):\n",
    "    r = j // plots_per_row\n",
    "    c = j % plots_per_row\n",
    "    axes[r, c].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    col for col in dataset.columns\n",
    "    if np.issubdtype(dataset[col].dtype, np.number) and dataset[col].nunique() > 10\n",
    "]\n",
    "\n",
    "plots_per_row = 3\n",
    "rows = math.ceil(len(numerical_cols) / plots_per_row)\n",
    "\n",
    "fig, axes = plt.subplots(rows, plots_per_row, figsize=(5 * plots_per_row, 4 * rows))\n",
    "axes = np.atleast_2d(axes) \n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    r = i // plots_per_row\n",
    "    c = i % plots_per_row\n",
    "    sns.histplot(data=dataset, x=col, kde=True, ax=axes[r, c], color='skyblue')\n",
    "    axes[r, c].set_title(f\"Distribution of {col}\")\n",
    "    axes[r, c].set_xlabel(col)\n",
    "\n",
    "total_subplots = rows * plots_per_row\n",
    "for j in range(i + 1, total_subplots):\n",
    "    r = j // plots_per_row\n",
    "    c = j % plots_per_row\n",
    "    axes[r, c].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifically, we can check the distribution relative to the two classes (stroke vs non-stroke)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    col for col in dataset.columns\n",
    "    if dataset[col].dtype == 'object' or dataset[col].nunique() <= 10\n",
    "]\n",
    "\n",
    "plots_per_row = 3\n",
    "rows = math.ceil(len(categorical_cols) / plots_per_row)\n",
    "\n",
    "fig, axes = plt.subplots(rows, plots_per_row, figsize=(5 * plots_per_row, 4 * rows))\n",
    "axes = axes if isinstance(axes, np.ndarray) else [[axes]]\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    r = i // plots_per_row\n",
    "    c = i % plots_per_row\n",
    "    \n",
    "    sns.countplot(x=col, hue='stroke', data=dataset, palette='viridis', ax=axes[r][c])\n",
    "    axes[r][c].set_title(f\"Distribution of {col} by Stroke Status\")\n",
    "    axes[r][c].tick_params(axis='x', rotation=45)\n",
    "\n",
    "total_subplots = rows * plots_per_row\n",
    "for j in range(i+1, total_subplots):\n",
    "    r = j // plots_per_row\n",
    "    c = j % plots_per_row\n",
    "    axes[r][c].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having the 'children' and 'never_worked' category at the same time can be tricky. That's because never worked doesn't seem to have a lot of data in general, while there are more records of children. Moreover, childrens can also be considered to be people that never worked. So, a decision can be merging the children and never_worked type for the work_type class into one: never_worked. In essence, this difference between individuals can also be made via the 'age' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[(dataset['work_type'] == 'children') & (dataset['ever_married'] == 'Yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=dataset, x='age', hue='work_type', multiple='stack', palette='viridis')\n",
    "plt.title('Distribution of Work Type by Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also notice this in the graph above. Therefore, a merging between 'Children' and 'Never Worked' is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[(dataset['work_type'] == 'children'), 'work_type'] = 'Never_worked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=dataset, x='age', hue='work_type', multiple='stack', palette='viridis')\n",
    "plt.title('Distribution of Work Type by Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    col for col in dataset.columns \n",
    "    if dataset[col].dtype != 'object' and dataset[col].nunique() > 10 and 'id' not in col.lower()\n",
    "]\n",
    "\n",
    "plots_per_row = 3\n",
    "rows = math.ceil(len(numerical_cols) / plots_per_row)\n",
    "\n",
    "fig, axes = plt.subplots(rows, plots_per_row, figsize=(5 * plots_per_row, 4 * rows))\n",
    "axes = np.atleast_2d(axes) \n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    r = i // plots_per_row\n",
    "    c = i % plots_per_row\n",
    "    \n",
    "    sns.histplot(data=dataset, x=col, hue='stroke', palette='viridis', ax=axes[r, c], kde=True)\n",
    "    axes[r, c].set_title(f\"Distribution of {col} by Stroke Status\")\n",
    "    axes[r, c].tick_params(axis='x', rotation=45)\n",
    "\n",
    "total_subplots = rows * plots_per_row\n",
    "for j in range(i + 1, total_subplots):\n",
    "    r = j // plots_per_row\n",
    "    c = j % plots_per_row\n",
    "    axes[r, c].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data for the workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the train-val-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "\n",
    "    temp_size = test_size + val_size\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=temp_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    test_frac = test_size / temp_size\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=test_frac, stratify=y_temp, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['stroke'])\n",
    "y = dataset['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, test_size=0.15, val_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.concat([X_train, y_train], axis=1)\n",
    "dataset_val = pd.concat([X_val, y_val], axis=1)\n",
    "dataset_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "dataset_train.to_csv('dataset_train.csv', index=False)\n",
    "dataset_val.to_csv('dataset_val.csv', index=False)\n",
    "dataset_test.to_csv('dataset_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_notebook(*args, parameters={}, **kwargs):\n",
    "    return papermill.execute_notebook(*args, parameters=parameters, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'final_models'\n",
    "\n",
    "models_path = 'workers/models/' + name\n",
    "workers_path = 'workers/notebooks/' + name\n",
    "\n",
    "for path in [models_path, workers_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "imbalanced_action = [0, 1, 2, 3, 4]\n",
    "use_PCA = [False]\n",
    "scale = [False, True]\n",
    "normalize = [False, True]\n",
    "feature_binning = [False, True]\n",
    "feature_selection_mode = [0, 1, 2]\n",
    "k_features = [2, 3, 4]\n",
    "threshold = [0.5]\n",
    "lr = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "model_type = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29]\n",
    "loss_type = [0, 2, 3, 4, 5, 6]\n",
    "\n",
    "parameters = set() \n",
    "\n",
    "for imb in imbalanced_action:\n",
    "    for pca in use_PCA:\n",
    "        for sc in scale:\n",
    "            for nm in normalize:\n",
    "                for fe in feature_binning:\n",
    "                    for fs in feature_selection_mode:\n",
    "                        for k in k_features:\n",
    "                            for t in threshold:\n",
    "                                for mt in model_type:\n",
    "                                    for learning_rate in lr:\n",
    "                                        for lt in loss_type:\n",
    "                                            if fe == True:\n",
    "                                                nm = False\n",
    "                                                sc = False\n",
    "                                            if fs == 2:\n",
    "                                                k = 0\n",
    "                                            bp = {\n",
    "                                                'imbalanced_action': imb,\n",
    "                                                'use_PCA': pca,\n",
    "                                                'scale': sc,\n",
    "                                                'normalize': nm,\n",
    "                                                'feature_binning': fe,\n",
    "                                                'feature_selection_mode': fs,\n",
    "                                                'k_features': k,\n",
    "                                                'threshold': t,\n",
    "                                                'model_type': mt,\n",
    "                                                'learning_rate': learning_rate,\n",
    "                                                'loss_type': lt\n",
    "                                            }\n",
    "                                            parameters.add(frozenset(bp.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor() as pool, tqdm(total=len(parameters)) as progress:\n",
    "    for idx, param in enumerate(parameters):\n",
    "        if idx > 55928:\n",
    "            param = dict(param)\n",
    "            param['model_file_path'] = f'{models_path}/stroke_model_{idx}.pkl'\n",
    "            param['pca_file_path'] = f'{models_path}/stroke_pca_{idx}.pkl'\n",
    "            param['scaler_file_path'] = f'{models_path}/stroke_scaler_{idx}.pkl'\n",
    "            param['normalizer_file_path'] = f'{models_path}/stroke_normalizer_{idx}.pkl'\n",
    "            param['encoder_file_path'] = f'{models_path}/stroke_encoder_{idx}.pkl' \n",
    "            execute_notebook(\n",
    "                'stroke_detection_worker_best.ipynb',\n",
    "                f'{workers_path}/stroke_model_{idx}.ipynb',\n",
    "                parameters=param\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting results from workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scrap(nb, scrap_name):\n",
    "    return nb.scraps[scrap_name].data if scrap_name in nb.scraps else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = [\n",
    "    \"parameters\",\n",
    "    \"precision_train\",\n",
    "    \"recall_train\",\n",
    "    \"f1_train\",\n",
    "    \"accuracy_train\",\n",
    "    \"precision_val\",\n",
    "    \"recall_val\",\n",
    "    \"f1_val\",\n",
    "    \"accuracy_val\",\n",
    "    \"pr_auc_val\",\n",
    "    \"precision_optimal\",\n",
    "    \"recall_optimal\",\n",
    "    \"f1_optimal\",\n",
    "    \"mcc_optimal\",\n",
    "    \"precision_optimal_f2\",\n",
    "    \"recall_optimal_f2\",\n",
    "    \"f2_optimal\",\n",
    "    \"mcc_optimal_f2\",\n",
    "    \"precision_test\",\n",
    "    \"recall_test\",\n",
    "    \"f1_test\",\n",
    "    \"accuracy_test\",\n",
    "    \"f2_test\",\n",
    "    \"mcc_test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "directory_path = workers_path\n",
    "output_csv_path = \"results.csv\"\n",
    "\n",
    "with open(output_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if not filename.endswith(\".ipynb\"):\n",
    "            continue\n",
    "\n",
    "        notebook_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            nb = scrapbook.read_notebook(notebook_path)\n",
    "            \n",
    "            row = {}\n",
    "            row[\"parameters\"] = json.dumps(nb.parameters)\n",
    "            \n",
    "            row[\"precision_train\"] = get_scrap(nb, \"precision_train\")\n",
    "            row[\"recall_train\"]    = get_scrap(nb, \"recall_train\")\n",
    "            row[\"f1_train\"]        = get_scrap(nb, \"f1_score_train\")\n",
    "            row[\"accuracy_train\"]  = get_scrap(nb, \"accuracy_score_train\")\n",
    "\n",
    "            row[\"precision_val\"]   = get_scrap(nb, \"precision\")\n",
    "            row[\"recall_val\"]      = get_scrap(nb, \"recall\")\n",
    "            row[\"f1_val\"]          = get_scrap(nb, \"f1_score\")\n",
    "            row[\"accuracy_val\"]    = get_scrap(nb, \"accuracy\")\n",
    "            row[\"pr_auc_val\"]      = get_scrap(nb, \"pr_auc\")\n",
    "\n",
    "            row[\"precision_optimal\"] = get_scrap(nb, \"precision_optimal_f1\")\n",
    "            row[\"recall_optimal\"]    = get_scrap(nb, \"recall_optimal_f1\")\n",
    "            row[\"f1_optimal\"]        = get_scrap(nb, \"f1_score_optimal\")\n",
    "            row[\"mcc_optimal\"]       = get_scrap(nb, \"mcc_optimal_f1\")\n",
    "\n",
    "            row[\"precision_optimal_f2\"] = get_scrap(nb, \"precision_optimal_f2\")\n",
    "            row[\"recall_optimal_f2\"]    = get_scrap(nb, \"recall_optimal_f2\")\n",
    "            row[\"f2_optimal\"]           = get_scrap(nb, \"f2_score_optimal_thres\")\n",
    "            row[\"mcc_optimal_f2\"]       = get_scrap(nb, \"mcc_optimal_f2\")\n",
    "\n",
    "            row[\"precision_test\"] = get_scrap(nb, \"precision_test\")\n",
    "            row[\"recall_test\"]    = get_scrap(nb, \"recall_test\")\n",
    "            row[\"f1_test\"]        = get_scrap(nb, \"f1_score_test\")\n",
    "            row[\"accuracy_test\"]  = get_scrap(nb, \"accuracy_score_test\")\n",
    "            row[\"f2_test\"]        = get_scrap(nb, \"f2_score_test\")\n",
    "            row[\"mcc_test\"]       = get_scrap(nb, \"mcc_test\")\n",
    "\n",
    "            writer.writerow(row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "results[\"params_dict\"] = results[\"parameters\"].apply(json.loads)        \n",
    "results = results.join(pd.json_normalize(results[\"params_dict\"]))          \n",
    "results.drop(columns=[\"parameters\", \"params_dict\"], inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_without_model_path = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_without_model_path = results_without_model_path.sort_values(by='f2_optimal', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_without_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_without_model_path.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_best = results_without_model_path[\n",
    "    (results_without_model_path['f2_test'] >= results_without_model_path['f2_optimal']) &\n",
    "     (results_without_model_path['recall_optimal_f2'] >= 0.7)\n",
    "]\n",
    "\n",
    "results_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_best.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thief-detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
